{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import cv2\n",
    "import os, random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras import backend as K\n",
    "import itertools\n",
    "import editdistance\n",
    "import json\n",
    "\n",
    "letters = \" #'()+,-./:0123456789ABCDEFGHIJKLMNOPQRSTUVWXYabcdeghiklmnopqrstuvxyzÂÊÔàáâãèéêìíòóôõùúýăĐđĩũƠơưạảấầẩậắằẵặẻẽếềểễệỉịọỏốồổỗộớờởỡợụủỨứừửữựỳỵỷỹ\"\n",
    "MAX_LEN = 70\n",
    "SIZE = 2560, 160\n",
    "CHAR_DICT = len(letters) + 1\n",
    "print(CHAR_DICT)\n",
    "\n",
    "# test label data\n",
    "# corpus = (json.load(open('labels.json', encoding ='utf8')))\n",
    "# print(corpus)\n",
    "\n",
    "\n",
    "\n",
    "def text_to_labels(text):\n",
    "    return list(map(lambda x: letters.index(x), text))\n",
    "\n",
    "def labels_to_text(labels):\n",
    "    return ''.join(list(map(lambda x: letters[x] if x < len(letters) else \"\", labels)))\n",
    "\n",
    "def ctc_lambda_func(args):\n",
    "    y_pred, labels, input_length, label_length = args\n",
    "    # the 2 is critical here since the first couple outputs of the RNN\n",
    "    # tend to be garbage:\n",
    "    y_pred = y_pred[:, 2:, :]\n",
    "    return K.ctc_batch_cost(labels, y_pred, input_length, label_length)\n",
    "\n",
    "def decode_batch(out):\n",
    "    ret = []\n",
    "    for j in range(out.shape[0]):\n",
    "        out_best = list(np.argmax(out[j, 2:], 1))\n",
    "        out_best = [k for k, g in itertools.groupby(out_best)]\n",
    "        outstr = labels_to_text(out_best)\n",
    "        ret.append(outstr)\n",
    "    return ret\n",
    "\n",
    "class VizCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, sess, y_func, text_img_gen, text_size, num_display_words=6):\n",
    "        self.y_func = y_func\n",
    "        self.text_img_gen = text_img_gen\n",
    "        self.num_display_words = num_display_words\n",
    "        self.text_size = text_size\n",
    "        self.sess = sess\n",
    "\n",
    "    def show_edit_distance(self, num):\n",
    "        num_left = num\n",
    "        mean_norm_ed = 0.0\n",
    "        mean_ed = 0.0\n",
    "        while num_left > 0:\n",
    "            word_batch = next(self.text_img_gen.next_batch())[0]\n",
    "            num_proc = min(word_batch['the_inputs'].shape[0], num_left)\n",
    "            # predict\n",
    "            inputs = word_batch['the_inputs'][0:num_proc]\n",
    "            pred = self.y_func([inputs])[0]\n",
    "            decoded_res = decode_batch(pred)\n",
    "            # label\n",
    "            labels = word_batch['the_labels'][:num_proc].astype(np.int32)\n",
    "            labels = [labels_to_text(label) for label in labels]\n",
    "            \n",
    "            for j in range(num_proc):\n",
    "                edit_dist = editdistance.eval(decoded_res[j], labels[j])\n",
    "                mean_ed += float(edit_dist)\n",
    "                mean_norm_ed += float(edit_dist) / len(labels[j])\n",
    "\n",
    "            num_left -= num_proc\n",
    "        mean_norm_ed = mean_norm_ed / num\n",
    "        mean_ed = mean_ed / num\n",
    "        print('\\nOut of %d samples:  Mean edit distance:'\n",
    "              '%.3f Mean normalized edit distance: %0.3f'\n",
    "              % (num, mean_ed, mean_norm_ed))\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        batch = next(self.text_img_gen.next_batch())[0]\n",
    "        inputs = batch['the_inputs'][:self.num_display_words]\n",
    "        labels = batch['the_labels'][:self.num_display_words].astype(np.int32)\n",
    "        labels = [labels_to_text(label) for label in labels]\n",
    "         \n",
    "        pred = self.y_func([inputs])[0]\n",
    "        pred_texts = decode_batch(pred)\n",
    "        for i in range(min(self.num_display_words, len(inputs))):\n",
    "            print(\"label: {} - predict: {}\".format(labels[i], pred_texts[i]))\n",
    "\n",
    "        self.show_edit_distance(self.text_size)\n",
    "\n",
    "class TextImageGenerator:\n",
    "    def __init__(self, img_dirpath, labels_path, img_w, img_h,\n",
    "                 batch_size, downsample_factor, idxs, training=True, max_text_len=9, n_eraser=5):\n",
    "        self.img_h = img_h\n",
    "        self.img_w = img_w\n",
    "        self.batch_size = batch_size\n",
    "        self.max_text_len = max_text_len\n",
    "        self.idxs = idxs\n",
    "        self.downsample_factor = downsample_factor\n",
    "        self.img_dirpath = img_dirpath                  # image dir path\n",
    "        self.labels= (json.load(open(labels_path, encoding ='utf8'))) if labels_path != None else None\n",
    "        self.img_dir = os.listdir(self.img_dirpath)     # images list\n",
    "        if self.idxs is not None:\n",
    "            self.img_dir = [self.img_dir[idx] for idx in self.idxs]\n",
    "\n",
    "        self.n = len(self.img_dir)                      # number of images\n",
    "        self.indexes = list(range(self.n))\n",
    "        self.cur_index = 0\n",
    "        self.imgs = np.zeros((self.n, self.img_h, self.img_w, 3), dtype=np.float16)\n",
    "        self.training = training\n",
    "        self.texts = []\n",
    "\n",
    "    def build_data(self):\n",
    "        print(self.n, \" Image Loading start... \", self.img_dirpath)\n",
    "        for i, img_file in enumerate(self.img_dir):\n",
    "            img = image.load_img(self.img_dirpath + img_file, target_size=SIZE[::-1])\n",
    "            img = image.img_to_array(img)\n",
    "            img = preprocess_input(img).astype(np.float16)\n",
    "            self.imgs[i] = img\n",
    "            if self.labels != None: \n",
    "                self.texts.append(self.labels[img_file])\n",
    "            else:\n",
    "                #valid mode\n",
    "                self.texts.append('')\n",
    "        print(\"Image Loading finish...\")\n",
    "\n",
    "    def next_sample(self):\n",
    "        self.cur_index += 1\n",
    "        if self.cur_index >= self.n:\n",
    "            self.cur_index = 0\n",
    "            random.shuffle(self.indexes)\n",
    "        return self.imgs[self.indexes[self.cur_index]].astype(np.float32), self.texts[self.indexes[self.cur_index]]\n",
    "\n",
    "    def next_batch(self):\n",
    "        while True:\n",
    "            X_data = np.zeros([self.batch_size, self.img_w, self.img_h, 3], dtype=np.float32)     # (bs, 128, 64, 1)\n",
    "            Y_data = np.zeros([self.batch_size, self.max_text_len], dtype=np.float32)             # (bs, 9)\n",
    "            input_length = np.ones((self.batch_size, 1), dtype=np.float32) * (self.img_w // self.downsample_factor - 2)  # (bs, 1)\n",
    "            label_length = np.zeros((self.batch_size, 1), dtype=np.float32)           # (bs, 1)\n",
    "\n",
    "            for i in range(self.batch_size):\n",
    "                img, text = self.next_sample()\n",
    "                img = img.transpose((1, 0, 2))\n",
    "                \n",
    "                X_data[i] = img\n",
    "                Y_data[i,:len(text)] = text_to_labels(text)\n",
    "                label_length[i] = len(text)\n",
    "\n",
    "            inputs = {\n",
    "                'the_inputs': X_data,  # (bs, 128, 64, 1)\n",
    "                'the_labels': Y_data,  # (bs, 8)\n",
    "                'input_length': input_length,  # (bs, 1)\n",
    "                'label_length': label_length  # (bs, 1)\n",
    "            }\n",
    "            outputs = {'ctc': np.zeros([self.batch_size])}   # (bs, 1)\n",
    "            yield (inputs, outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_shape:  (2560, 160, 3)\n",
      "Tensor(\"vgg16_1/block5_pool/MaxPool:0\", shape=(?, 80, 5, 512), dtype=float32)\n",
      "inner:  Tensor(\"reshape_1/Reshape:0\", shape=(?, 80, 5), dtype=float32)\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "the_inputs (InputLayer)         (None, 2560, 160, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vgg16 (Model)                   multiple             14714688    the_inputs[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 80, 5)        0           vgg16[1][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense1 (Dense)                  (None, 80, 512)      3072        reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 80, 512)      0           dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 80, 1024)     4198400     dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense2 (Dense)                  (None, 80, 140)      143500      bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "the_labels (InputLayer)         (None, 70)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_length (InputLayer)       (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "label_length (InputLayer)       (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ctc (Lambda)                    (None, 1)            0           dense2[0][0]                     \n",
      "                                                                 the_labels[0][0]                 \n",
      "                                                                 input_length[0][0]               \n",
      "                                                                 label_length[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 19,059,660\n",
      "Trainable params: 4,344,972\n",
      "Non-trainable params: 14,714,688\n",
      "__________________________________________________________________________________________________\n",
      "train_idx:  [ 365  366  367 ... 1820 1821 1822]\n",
      "valid_idx:  [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
      " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
      " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
      " 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n",
      " 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215\n",
      " 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233\n",
      " 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251\n",
      " 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269\n",
      " 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287\n",
      " 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305\n",
      " 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323\n",
      " 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341\n",
      " 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359\n",
      " 360 361 362 363 364]\n",
      "1458  Image Loading start...  image_train/\n",
      "Image Loading finish...\n",
      "365  Image Loading start...  image_train/\n",
      "Image Loading finish...\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Input to reshape is a tensor with 614400 values, but the requested shape has 1200\n\t [[{{node reshape_1/Reshape}}]]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-5fc161056824>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[1;31m# img = os.listdir('image_train/')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'image_train/'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'labels.json'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.001\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-3-5fc161056824>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(datapath, labelpath, epochs, batch_size, lr, finetune)\u001b[0m\n\u001b[0;32m     97\u001b[0m     \u001b[0mkfold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mKFold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnsplits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2018\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnfiles\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnsplits\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m         \u001b[0mtrain_kfold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkfold\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdatapath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabelpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinetune\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;31m# if __name__=='__main__':\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-5fc161056824>\u001b[0m in \u001b[0;36mtrain_kfold\u001b[1;34m(idx, kfold, datapath, labelpath, epochs, batch_size, lr, finetune)\u001b[0m\n\u001b[0;32m     88\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mckp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mearlystop\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalid_generator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m                     validation_steps=int(len(valid_idx) / batch_size))\n\u001b[0m\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatapath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabelpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinetune\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1424\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1425\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1426\u001b[1;33m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1427\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1428\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[1;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, **kwargs)\u001b[0m\n\u001b[0;32m    189\u001b[0m       \u001b[0mprogbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 191\u001b[1;33m       \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    192\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[0;32m   1189\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1190\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_fit_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1191\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1192\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1193\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3074\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3075\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[1;32m-> 3076\u001b[1;33m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[0;32m   3077\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3078\u001b[0m     return nest.pack_sequence_as(self._outputs_structure,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[0;32m    526\u001b[0m             \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    527\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 528\u001b[1;33m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[0;32m    529\u001b[0m     \u001b[1;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m     \u001b[1;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Input to reshape is a tensor with 614400 values, but the requested shape has 1200\n\t [[{{node reshape_1/Reshape}}]]"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from sklearn.model_selection import KFold\n",
    "import keras\n",
    "from tensorflow.keras.layers import Input, Dense, Activation, Bidirectional, Dropout\n",
    "from tensorflow.keras.layers import Reshape, Lambda, BatchNormalization\n",
    "from tensorflow.keras import applications\n",
    "from tensorflow.keras.layers import LSTM\n",
    "# from tensorflow.keras.layers.merge import add, concatenate\n",
    "from tensorflow.keras.layers import add, concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adadelta, Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler, ModelCheckpoint, TensorBoard, ReduceLROnPlateau\n",
    "# from loader import TextImageGenerator, MAX_LEN, CHAR_DICT, SIZE, VizCallback, ctc_lambda_func\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "# from keras import backend as K\n",
    "# from tensorflow.compat.v1.keras import backend as K\n",
    "from tensorflow.python.keras import backend as K\n",
    "import argparse\n",
    "\n",
    "# Draw images\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def get_model(input_shape, training, finetune):\n",
    "    print('input_shape: ', input_shape)\n",
    "    inputs = Input(name='the_inputs', shape=input_shape, dtype='float32')\n",
    "    base_model = applications.VGG16(weights='imagenet', include_top=False)\n",
    "    inner = base_model(inputs)\n",
    "    print(inner)\n",
    "#     inner = Reshape(target_shape=(int(inner.shape[1]), -1), name='reshape')(inner)\n",
    "    inner = Reshape(target_shape=(int(inner.shape[1]), 5), name='reshape')(inner)\n",
    "    print('inner: ', inner)\n",
    "    inner = Dense(512, activation='relu', kernel_initializer='he_normal', name='dense1')(inner) \n",
    "    inner = Dropout(0.25)(inner) \n",
    "    lstm = Bidirectional(LSTM(512, return_sequences=True, kernel_initializer='he_normal', name='lstm1', dropout=0.25, recurrent_dropout=0.25))(inner) \n",
    "\n",
    "    y_pred = Dense(CHAR_DICT, activation='softmax', kernel_initializer='he_normal',name='dense2')(lstm)\n",
    "    \n",
    "    labels = Input(name='the_labels', shape=[MAX_LEN], dtype='float32')\n",
    "    input_length = Input(name='input_length', shape=[1], dtype='int64')\n",
    "    label_length = Input(name='label_length', shape=[1], dtype='int64')\n",
    "\n",
    "    loss_out = Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')([y_pred, labels, input_length, label_length])\n",
    "\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = finetune\n",
    "    \n",
    "    y_func = K.function([inputs], [y_pred])\n",
    "    \n",
    "    if training:\n",
    "        Model(inputs=[inputs, labels, input_length, label_length], outputs=loss_out).summary()\n",
    "        return Model(inputs=[inputs, labels, input_length, label_length], outputs=loss_out), y_func\n",
    "    else:\n",
    "        return Model(inputs=[inputs], outputs=y_pred)\n",
    "\n",
    "def train_kfold(idx, kfold, datapath, labelpath,  epochs, batch_size, lr, finetune):\n",
    "    sess = tf.Session()\n",
    "    K.set_session(sess)\n",
    "\n",
    "    model, y_func = get_model((*SIZE, 3), training=True, finetune=finetune)\n",
    "    ada = Adam(lr=lr)\n",
    "    model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=ada)\n",
    "    \n",
    "    ## load data\n",
    "    train_idx, valid_idx = kfold[idx]\n",
    "    print('train_idx: ',  train_idx)\n",
    "    print('valid_idx: ', valid_idx)\n",
    "    train_generator = TextImageGenerator(datapath, labelpath, *SIZE, batch_size, 32, train_idx, True, MAX_LEN)\n",
    "    train_generator.build_data()\n",
    "    valid_generator  = TextImageGenerator(datapath, labelpath, *SIZE, batch_size, 32, valid_idx, False, MAX_LEN)\n",
    "    valid_generator.build_data()\n",
    "\n",
    "    ## callbacks\n",
    "    weight_path = 'model/best_%d.h5' % idx\n",
    "    ckp = ModelCheckpoint(weight_path, monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=True)\n",
    "    vis = VizCallback(sess, y_func, valid_generator, len(valid_idx))\n",
    "    earlystop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=0, mode='min')\n",
    "\n",
    "    if finetune:\n",
    "        print('load pretrain model')\n",
    "        model.load_weights(weight_path)\n",
    "\n",
    "    model.fit_generator(generator=train_generator.next_batch(),\n",
    "                    steps_per_epoch=int(len(train_idx) / batch_size),\n",
    "                    epochs=epochs,\n",
    "                    callbacks=[ckp, vis, earlystop],\n",
    "                    validation_data=valid_generator.next_batch(),\n",
    "                    validation_steps=int(len(valid_idx) / batch_size))\n",
    "    \n",
    "def train(datapath, labelpath, epochs, batch_size, lr, finetune=False):\n",
    "    nsplits = 5\n",
    "\n",
    "    nfiles = np.arange(len(os.listdir(datapath)))\n",
    "\n",
    "    kfold = list(KFold(nsplits, random_state=2018).split(nfiles))\n",
    "    for idx in range(nsplits):\n",
    "        train_kfold(idx, kfold, datapath, labelpath, epochs, batch_size, lr, finetune)\n",
    "\n",
    "# if __name__=='__main__':\n",
    "#     parser = argparse.ArgumentParser()\n",
    "#     parser.add_argument(\"--train\", default='C:/Users/PC/Desktop/OCR/image_train/', type=str)\n",
    "#     parser.add_argument(\"--label\", default='C:/Users/PC/Desktop/OCR/labels.json', type=str)\n",
    "\n",
    "#     parser.add_argument(\"--epochs\", default=100, type=int)\n",
    "#     parser.add_argument('--batch_size', default=3, type=int)\n",
    "#     parser.add_argument('--device', default=1, type=int)\n",
    "#     parser.add_argument('--finetune', default=0, type=int)\n",
    "#     parser.add_argument('--lr', default=0.001, type=float)\n",
    "#     args = parser.parse_args()\n",
    "\n",
    "#     os.environ[\"CUDA_VISIBLE_DEVICES\"]=str(args.device)\n",
    "\n",
    "#     train(args.train, args.label, args.epochs, args.batch_size, args.lr, args.finetune)\n",
    "\n",
    "\n",
    "\n",
    "# img = image.load_img('0000_samples.png',target_size=SIZE[::-1])\n",
    "# plt.imshow(img)\n",
    "# img = os.listdir('image_train/')\n",
    "\n",
    "train('image_train/','labels.json',100, 3, 0.001, False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
