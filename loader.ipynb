{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-d99cce9d6ca0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    161\u001b[0m             \u001b[1;32myield\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 163\u001b[1;33m \u001b[0mtrain_generator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextImageGenerator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'image_train/'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'labels.json'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mSIZE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m365\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1822\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMAX_LEN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    164\u001b[0m \u001b[0mtrain_generator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-35-d99cce9d6ca0>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, img_dirpath, labels_path, img_w, img_h, batch_size, downsample_factor, idxs, training, max_text_len, n_eraser)\u001b[0m\n\u001b[0;32m    112\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindexes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcur_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimgs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimg_h\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimg_w\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat16\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    115\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtexts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import json\n",
    "import cv2\n",
    "import os, random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras import backend as K\n",
    "import itertools\n",
    "import editdistance\n",
    "import json\n",
    "\n",
    "letters = \" #'()+,-./:0123456789ABCDEFGHIJKLMNOPQRSTUVWXYabcdeghiklmnopqrstuvxyzÂÊÔàáâãèéêìíòóôõùúýăĐđĩũƠơưạảấầẩậắằẵặẻẽếềểễệỉịọỏốồổỗộớờởỡợụủỨứừửữựỳỵỷỹ\"\n",
    "MAX_LEN = 70\n",
    "SIZE = 2560, 160\n",
    "CHAR_DICT = len(letters) + 1\n",
    "print(CHAR_DICT)\n",
    "\n",
    "# test label data\n",
    "# corpus = (json.load(open('labels.json', encoding ='utf8')))\n",
    "# print(corpus)\n",
    "\n",
    "\n",
    "\n",
    "def text_to_labels(text):\n",
    "    return list(map(lambda x: letters.index(x), text))\n",
    "\n",
    "def labels_to_text(labels):\n",
    "    return ''.join(list(map(lambda x: letters[x] if x < len(letters) else \"\", labels)))\n",
    "\n",
    "def ctc_lambda_func(args):\n",
    "    y_pred, labels, input_length, label_length = args\n",
    "    # the 2 is critical here since the first couple outputs of the RNN\n",
    "    # tend to be garbage:\n",
    "    y_pred = y_pred[:, 2:, :]\n",
    "    return K.ctc_batch_cost(labels, y_pred, input_length, label_length)\n",
    "\n",
    "def decode_batch(out):\n",
    "    ret = []\n",
    "    for j in range(out.shape[0]):\n",
    "        out_best = list(np.argmax(out[j, 2:], 1))\n",
    "        out_best = [k for k, g in itertools.groupby(out_best)]\n",
    "        outstr = labels_to_text(out_best)\n",
    "        ret.append(outstr)\n",
    "    return ret\n",
    "\n",
    "class VizCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, sess, y_func, text_img_gen, text_size, num_display_words=6):\n",
    "        self.y_func = y_func\n",
    "        self.text_img_gen = text_img_gen\n",
    "        self.num_display_words = num_display_words\n",
    "        self.text_size = text_size\n",
    "        self.sess = sess\n",
    "\n",
    "    def show_edit_distance(self, num):\n",
    "        num_left = num\n",
    "        mean_norm_ed = 0.0\n",
    "        mean_ed = 0.0\n",
    "        while num_left > 0:\n",
    "            word_batch = next(self.text_img_gen.next_batch())[0]\n",
    "            num_proc = min(word_batch['the_inputs'].shape[0], num_left)\n",
    "            # predict\n",
    "            inputs = word_batch['the_inputs'][0:num_proc]\n",
    "            pred = self.y_func([inputs])[0]\n",
    "            decoded_res = decode_batch(pred)\n",
    "            # label\n",
    "            labels = word_batch['the_labels'][:num_proc].astype(np.int32)\n",
    "            labels = [labels_to_text(label) for label in labels]\n",
    "            \n",
    "            for j in range(num_proc):\n",
    "                edit_dist = editdistance.eval(decoded_res[j], labels[j])\n",
    "                mean_ed += float(edit_dist)\n",
    "                mean_norm_ed += float(edit_dist) / len(labels[j])\n",
    "\n",
    "            num_left -= num_proc\n",
    "        mean_norm_ed = mean_norm_ed / num\n",
    "        mean_ed = mean_ed / num\n",
    "        print('\\nOut of %d samples:  Mean edit distance:'\n",
    "              '%.3f Mean normalized edit distance: %0.3f'\n",
    "              % (num, mean_ed, mean_norm_ed))\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        batch = next(self.text_img_gen.next_batch())[0]\n",
    "        inputs = batch['the_inputs'][:self.num_display_words]\n",
    "        labels = batch['the_labels'][:self.num_display_words].astype(np.int32)\n",
    "        labels = [labels_to_text(label) for label in labels]\n",
    "         \n",
    "        pred = self.y_func([inputs])[0]\n",
    "        pred_texts = decode_batch(pred)\n",
    "        for i in range(min(self.num_display_words, len(inputs))):\n",
    "            print(\"label: {} - predict: {}\".format(labels[i], pred_texts[i]))\n",
    "\n",
    "        self.show_edit_distance(self.text_size)\n",
    "\n",
    "class TextImageGenerator:\n",
    "    def __init__(self, img_dirpath, labels_path, img_w, img_h,\n",
    "                 batch_size, downsample_factor, idxs, training=True, max_text_len=9, n_eraser=5):\n",
    "        self.img_h = img_h\n",
    "        self.img_w = img_w\n",
    "        self.batch_size = batch_size\n",
    "        self.max_text_len = max_text_len\n",
    "        self.idxs = idxs\n",
    "        self.downsample_factor = downsample_factor\n",
    "        self.img_dirpath = img_dirpath                  # image dir path\n",
    "        self.labels= (json.load(open(labels_path, encoding ='utf8'))) if labels_path != None else None\n",
    "        self.img_dir = os.listdir(self.img_dirpath)     # images list\n",
    "        if self.idxs is not None:\n",
    "            self.img_dir = [self.img_dir[idx] for idx in self.idxs]\n",
    "\n",
    "        self.n = len(self.img_dir)                      # number of images\n",
    "        self.indexes = list(range(self.n))\n",
    "        self.cur_index = 0\n",
    "        self.imgs = np.zeros((self.n, self.img_h, self.img_w, 3), dtype=np.float16)\n",
    "        self.training = training\n",
    "        self.texts = []\n",
    "\n",
    "    def build_data(self):\n",
    "        print(self.n, \" Image Loading start... \", self.img_dirpath)\n",
    "        for i, img_file in enumerate(self.img_dir):\n",
    "            img = image.load_img(self.img_dirpath + img_file, target_size=SIZE[::-1])\n",
    "            img = image.img_to_array(img)\n",
    "            img = preprocess_input(img).astype(np.float16)\n",
    "            self.imgs[i] = img\n",
    "            if self.labels != None: \n",
    "                self.texts.append(self.labels[img_file])\n",
    "            else:\n",
    "                #valid mode\n",
    "                self.texts.append('')\n",
    "        print(\"Image Loading finish...\")\n",
    "\n",
    "    def next_sample(self):\n",
    "        self.cur_index += 1\n",
    "        if self.cur_index >= self.n:\n",
    "            self.cur_index = 0\n",
    "            random.shuffle(self.indexes)\n",
    "        return self.imgs[self.indexes[self.cur_index]].astype(np.float32), self.texts[self.indexes[self.cur_index]]\n",
    "\n",
    "    def next_batch(self):\n",
    "        while True:\n",
    "            X_data = np.zeros([self.batch_size, self.img_w, self.img_h, 3], dtype=np.float32)     # (bs, 128, 64, 1)\n",
    "            Y_data = np.zeros([self.batch_size, self.max_text_len], dtype=np.float32)             # (bs, 9)\n",
    "            input_length = np.ones((self.batch_size, 1), dtype=np.float32) * (self.img_w // self.downsample_factor - 2)  # (bs, 1)\n",
    "            label_length = np.zeros((self.batch_size, 1), dtype=np.float32)           # (bs, 1)\n",
    "\n",
    "            for i in range(self.batch_size):\n",
    "                img, text = self.next_sample()\n",
    "                img = img.transpose((1, 0, 2))\n",
    "                \n",
    "                X_data[i] = img\n",
    "                Y_data[i,:len(text)] = text_to_labels(text)\n",
    "                label_length[i] = len(text)\n",
    "\n",
    "            inputs = {\n",
    "                'the_inputs': X_data,  # (bs, 128, 64, 1)\n",
    "                'the_labels': Y_data,  # (bs, 8)\n",
    "                'input_length': input_length,  # (bs, 1)\n",
    "                'label_length': label_length  # (bs, 1)\n",
    "            }\n",
    "            outputs = {'ctc': np.zeros([self.batch_size])}   # (bs, 1)\n",
    "            yield (inputs, outputs)\n",
    "\n",
    "train_generator = TextImageGenerator('image_train/', 'labels.json', *SIZE, 3, 32, np.arange(365, 1822), True, MAX_LEN)\n",
    "train_generator.build_data()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
